{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.Posibilities = self.data.columns[3:15]\n",
    "        self.X = self.data['Text']\n",
    "        # make a dictionary of the words in X\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab_size = 0\n",
    "        for sentence in self.X:\n",
    "            for word in sentence.split():\n",
    "                if word not in self.word2idx:\n",
    "                    self.word2idx[word] = self.vocab_size\n",
    "                    self.idx2word[self.vocab_size] = word\n",
    "                    self.vocab_size += 1\n",
    "        # Apply the dictionary to X\n",
    "        self.X = self.X.apply(lambda x: [self.word2idx[word] for word in x.split()])\n",
    "        self.X_data = []\n",
    "        for sentence in self.X:\n",
    "            self.X_data.append(torch.tensor(sentence))\n",
    "        self.Y = self.data[self.Posibilities]\n",
    "        # make tensor of Y\n",
    "        self.Y = torch.tensor(self.Y.values, dtype=torch.float32)\n",
    "        # convert the Y to True/False to 1/0\n",
    "        self.Y = self.Y.apply_(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_data[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "dataset = ToxicDataset('archive/youtoxic_english_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "25\n",
      "tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "77\n",
      "tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "107\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "47\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "20\n",
      "tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n",
      "37\n",
      "tensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "57\n",
      "tensor([1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.])\n",
      "5\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "9\n",
      "tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "43\n",
      "tensor([1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(dataset):\n",
    "    print (len(data[0]))\n",
    "    print (data[1])\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "class ToxicModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, hidden_size, output_size):\n",
    "        super(ToxicModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Input: (seq_len, batch, input_size)\n",
    "        # input is a batch of sentences\n",
    "        # hidden is the hidden state of the lstm\n",
    "        # output is the output of the lstm\n",
    "        # hidden is the hidden state of the lstm\n",
    "        # output is the output of the lstm\n",
    "        output = self.embedding(input)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.linear1(output)\n",
    "        output = self.linear2(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size),\n",
    "                torch.zeros(1, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = ToxicModel(dataset.vocab_size, 128, len(dataset.Posibilities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the loss function\n",
    "criterion = nn.BCELoss()\n",
    "# Create the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train(model, data, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        tot_loss = 0\n",
    "        # initialize the hidden state\n",
    "        for i in tqdm(range(len(data))):\n",
    "            x, y = data[i][0], data[i][1]\n",
    "            x = x.unsqueeze(1)\n",
    "            hidden = model.initHidden()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            # take the last output of the lstm\n",
    "            output, hidden = model(x, hidden)\n",
    "            output = output[-1].squeeze(0)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tot_loss += loss.item()\n",
    "        \n",
    "        print('Epoch: {} - Loss: {:.6f}'.format(epoch, tot_loss / len(data)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:22<00:00, 45.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 0.004008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 35.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Loss: 0.002135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 63/1000 [00:01<00:28, 32.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Felipe de Jesus\\OneDrive\\Documentos\\Programaciones\\VisualStudio\\Python\\MachineLearning\\TwitterToxicity\\MainTwitter.ipynb Celda 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Felipe%20de%20Jesus/OneDrive/Documentos/Programaciones/VisualStudio/Python/MachineLearning/TwitterToxicity/MainTwitter.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Felipe%20de%20Jesus/OneDrive/Documentos/Programaciones/VisualStudio/Python/MachineLearning/TwitterToxicity/MainTwitter.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, dataset, criterion, optimizer, epochs)\n",
      "\u001b[1;32mc:\\Users\\Felipe de Jesus\\OneDrive\\Documentos\\Programaciones\\VisualStudio\\Python\\MachineLearning\\TwitterToxicity\\MainTwitter.ipynb Celda 11\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felipe%20de%20Jesus/OneDrive/Documentos/Programaciones/VisualStudio/Python/MachineLearning/TwitterToxicity/MainTwitter.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felipe%20de%20Jesus/OneDrive/Documentos/Programaciones/VisualStudio/Python/MachineLearning/TwitterToxicity/MainTwitter.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Felipe%20de%20Jesus/OneDrive/Documentos/Programaciones/VisualStudio/Python/MachineLearning/TwitterToxicity/MainTwitter.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felipe%20de%20Jesus/OneDrive/Documentos/Programaciones/VisualStudio/Python/MachineLearning/TwitterToxicity/MainTwitter.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     tot_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Felipe%20de%20Jesus/OneDrive/Documentos/Programaciones/VisualStudio/Python/MachineLearning/TwitterToxicity/MainTwitter.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m - Loss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch, tot_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(data)))\n",
      "File \u001b[1;32mc:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\torch\\optim\\optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    158\u001b[0m          grads,\n\u001b[0;32m    159\u001b[0m          exp_avgs,\n\u001b[0;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    162\u001b[0m          state_steps,\n\u001b[0;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m func(params,\n\u001b[0;32m    214\u001b[0m      grads,\n\u001b[0;32m    215\u001b[0m      exp_avgs,\n\u001b[0;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    218\u001b[0m      state_steps,\n\u001b[0;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[1;32mc:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\torch\\optim\\adam.py:309\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m--> 309\u001b[0m param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train(model, dataset, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsToxic 0.9999912\n",
      "IsAbusive 0.9999945\n",
      "IsThreat 8.0006345e-08\n",
      "IsProvocative 5.613571e-08\n",
      "IsObscene 0.016929762\n",
      "IsHatespeech 8.516501e-08\n",
      "IsRacist 2.4437388e-09\n",
      "IsNationalist 1.0034225e-10\n",
      "IsSexist 1.2508373e-09\n",
      "IsHomophobic 2.2771544e-13\n",
      "IsReligiousHate 3.0460438e-08\n",
      "IsRadicalism 3.6108947e-13\n"
     ]
    }
   ],
   "source": [
    "# make a sample text for the model\n",
    "sample = \"I though you was a good person, but i realize that you are Black, a fucking idiot\"\n",
    "sample = sample.split()\n",
    "# convert the sample to a tensor\n",
    "sample = torch.tensor([dataset.word2idx[word] for word in sample])\n",
    "# unsqueeze the tensor to make it a batch\n",
    "sample = sample.unsqueeze(1)\n",
    "# initialize the hidden state\n",
    "hidden = model.initHidden()\n",
    "# get the output of the model\n",
    "output, hidden = model(sample, hidden)\n",
    "# get the last output of the lstm\n",
    "output = output[-1].squeeze(0)\n",
    "# get the prediction\n",
    "prediction = output.detach().numpy()\n",
    "# get the posibilities\n",
    "posibilities = dataset.Posibilities\n",
    "# print the results as Posibility: probability\n",
    "for i in range(len(posibilities)):\n",
    "    print (posibilities[i], prediction[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('MLearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9178488e902897ccede7ccf72145ea4bf1db4863c1b153f9ec9b532ffe6212a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
